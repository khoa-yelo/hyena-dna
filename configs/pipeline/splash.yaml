# @package _global_
defaults:
  - /trainer: default
  - /loader: default
  - /dataset: splash_pretrain
  - /optimizer: adamw
  - /scheduler: cosine_warmup
  - /callbacks: [base, checkpoint]

train:
  monitor: test/loss
  mode: min

task:
  _name_: lm
  loss: 
    _name_: cross_entropy # potentially create a new cross_entropy loss that includes weights for uncertain tokens
    ignore_index: 4 # pad token (X token separate anchor-target pairs or N should be replaced to pad if we want to ignore them)
  torchmetrics: ['perplexity', 'num_tokens']

encoder: null
decoder: null
